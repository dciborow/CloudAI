{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ML tools to bring in data and learn how to do it.\n",
    "\n",
    "This notbook performs the following tasks:\n",
    "    - Load the dataset from the dprep file\n",
    "    - Stratify split the data into two sets one for training one for testing\n",
    "    - Serialize that model using pickle\n",
    "    - Upload the model to Azure Storage\n",
    "    - Download the model from Azure Storage and test it out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and constant values\n",
    "\n",
    "This section contains the neccesary imports and constants that will be used throughout the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Azure Machine Learning data collector to log various metrics\n",
    "from azureml.logging import get_azureml_logger\n",
    "logger = get_azureml_logger()\n",
    "\n",
    "# Use the Azure Machine Learning data preparation package\n",
    "from azureml.dataprep import package\n",
    "\n",
    "# Data manipulation/random generation from pandas and numpy\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Using the ski-kit leanr, this will fail if it has not been added as a dependency\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Serialize models\n",
    "import pickle\n",
    "\n",
    "# Azure Storage for uploading the output model\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from azure.storage.blob import PublicAccess\n",
    "from azure.storage.blob import ContentSettings\n",
    "\n",
    "# Azure storage and file name information\n",
    "AZURE_STORAGE_ACCOUNT_NAME = \"<STORAGE_ACCOUNT_NAME>\"\n",
    "AZURE_STORAGE_ACCOUNT_KEY = \"<STORAGE_ACCOUNT_KEY>\"\n",
    "AZURE_STORAGE_CONTAINER_NAME = \"readydemo\"\n",
    "AZURE_STORAGE_BLOB_NAME = \"factory.pkl\"\n",
    "\n",
    "LOCAL_SYSTEM_DIRECTORY = \"modelfile\"\n",
    "LOCAL_MODEL_FILE  = \"./{}/{}\".format(LOCAL_SYSTEM_DIRECTORY,AZURE_STORAGE_BLOB_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from the dataflow in workbench\n",
    "\n",
    "This code, along with some imports above, were provided when right clicking on the dprep file and choosing \n",
    "__Generate Data Access Code File__ in the Azure ML Workbench tool.\n",
    "\n",
    "This cell loads in the data we will use for training and testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(temp=45.9842594460449, volt=150.513223075022, rotate=277.294013981084, state=0.0, time=1.0, id=1.0),\n",
       " Row(temp=52.9039296937009, volt=110.434075269674, rotate=314.586726208661, state=0.0, time=2.0, id=1.0),\n",
       " Row(temp=53.8255072204536, volt=169.259518750327, rotate=315.602502059127, state=0.0, time=3.0, id=1.0),\n",
       " Row(temp=47.7826759112912, volt=110.829531516979, rotate=345.894651732999, state=0.0, time=4.0, id=1.0),\n",
       " Row(temp=43.4792263968699, volt=199.351674834705, rotate=325.36408065582, state=1.0, time=5.0, id=1.0)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This call will load the referenced package and return a DataFrame.\n",
    "# If run in a PySpark environment, this call returns a\n",
    "# Spark DataFrame. If not, it will return a Pandas DataFrame.\n",
    "projectDataFrame = package.run('dataset.dprep', dataflow_idx=0)\n",
    "\n",
    "# Remove this line and add code that uses the DataFrame\n",
    "projectDataFrame.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create datasets for training and testing \n",
    "\n",
    "We first search the data to determine how many successes and how many failures we have. In that process we determine that\n",
    "the data is heavily weighted towards succesful devices. \n",
    "\n",
    "To ensure that we have reasonable data for both testing and training we will:\n",
    "    - Split the data up into two buckets, succesful data and failed data\n",
    "    - Randomly choose approximately 70% of the data from each bucket for training and the remaining 30% for testing.\n",
    "    \n",
    "This type of split stratifies the data to ensure that neither set is too heavlily weighted to either class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 10000 records, 8316 are devices that are OK, and 1684 are in a failure state\n",
      "\n",
      "Training Data: 7045 records\n",
      "         temp        volt      rotate  state  time   id\n",
      "2   53.825507  169.259519  315.602502    0.0   3.0  1.0\n",
      "5   49.593767  145.642949  370.523147    0.0   6.0  1.0\n",
      "13  51.258633  180.305387  364.673218    0.0  14.0  1.0\n",
      "14  47.227808  175.518532  317.506728    0.0  15.0  1.0\n",
      "15  47.542005  163.243283  394.942473    0.0  16.0  1.0\n",
      "\n",
      "Testing Data : 2955 records\n",
      "        temp        volt      rotate  state  time   id\n",
      "0  45.984259  150.513223  277.294014    0.0   1.0  1.0\n",
      "1  52.903930  110.434075  314.586726    0.0   2.0  1.0\n",
      "3  47.782676  110.829532  345.894652    0.0   4.0  1.0\n",
      "7  49.624689  150.472998  310.409819    0.0   8.0  1.0\n",
      "8  48.660651  155.330066  342.176581    0.0   9.0  1.0\n",
      "CPU times: user 50.5 ms, sys: 16.6 ms, total: 67 ms\n",
      "Wall time: 579 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Using Ubuntu we have a PySpark environment, create a pandas data frame\n",
    "machinereadings = projectDataFrame.toPandas()\n",
    "\n",
    "# Split the datasets into successful devices and failed devices.\n",
    "successrows = machinereadings.loc[machinereadings['state'] == 0]\n",
    "failurerows = machinereadings.loc[machinereadings['state'] == 1]\n",
    "\n",
    "print(\"Of the {} records, {} are devices that are OK, and {} are in a failure state\".format(len(machinereadings), len(successrows), len(failurerows)))\n",
    "print(\"\")\n",
    "\n",
    "# Numpy will create us a boolean array of the length we want randomly selecting true and false. This allows us \n",
    "# to choose 0.7(~70%) of the succesful and failed devices.\n",
    "successmsk = np.random.rand(len(successrows)) < 0.7\n",
    "failuremsk = np.random.rand(len(failurerows)) < 0.7\n",
    "\n",
    "# For training take the 70% of items for each in the training set\n",
    "trainingDataFrame = pd.concat([successrows[successmsk], failurerows[failuremsk]])\n",
    "# For testing take the remaining 30% of items for each in the testing set\n",
    "testingDataFrame = pd.concat([successrows[~successmsk], failurerows[~failuremsk]])\n",
    "\n",
    "print(\"Training Data: {} records\".format(len(trainingDataFrame)))\n",
    "print(trainingDataFrame.head(5))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Testing Data : {} records\".format(len(testingDataFrame)))\n",
    "print(testingDataFrame.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model\n",
    "\n",
    "The next step after splitting the data is to train a model. We are using a two class decision model here which is well suited to\n",
    "DecisionTree. \n",
    "\n",
    "We use __ski-kit learn__ DecisionTreeClassifier as the model, train it with our training data then report on feature importance after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of fitting the classifier with the training data:\n",
      "Feature Columns: ['temp', 'volt', 'rotate', 'time', 'id']\n",
      "Feature Importance: [ 0.30984062  0.29348829  0.29527884  0.07128591  0.03010634]\n"
     ]
    }
   ],
   "source": [
    "# We need to know which of the columns in our dataset are to be used as features, so we identify them here.\n",
    "featureColumnNames = [\"temp\", \"volt\", \"rotate\", \"time\", \"id\"] \n",
    "\n",
    "# We set up two sets, one of features and one for labels\n",
    "trainingFeatures = trainingDataFrame[featureColumnNames]\n",
    "trainingLabels = trainingDataFrame[\"state\"]\n",
    "\n",
    "# fit/train the model with the training data\n",
    "decisionTreeClassifier = DecisionTreeClassifier()\n",
    "decisionTreeClassifier.fit(trainingFeatures, trainingLabels)\n",
    "\n",
    "# Report on the feature importance, note that the time and id fields hold very little value to \n",
    "# determining our success or failure rate. In a real case, these fields would likely be left out\n",
    "# of the decision making process before production.\n",
    "print(\"Results of fitting the classifier with the training data:\")\n",
    "print(\"Feature Columns: {}\".format(featureColumnNames))\n",
    "print(\"Feature Importance: {}\".format(decisionTreeClassifier.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model \n",
    "\n",
    "Using our testing data (the 30% of the original dataset) we score the model by predicting results only passing in the feature columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction results using the testing data:\n",
      "        temp        volt      rotate  state  time   id  prediction\n",
      "0  45.984259  150.513223  277.294014    0.0   1.0  1.0         0.0\n",
      "1  52.903930  110.434075  314.586726    0.0   2.0  1.0         1.0\n",
      "2  47.782676  110.829532  345.894652    0.0   4.0  1.0         0.0\n",
      "3  49.624689  150.472998  310.409819    0.0   8.0  1.0         0.0\n",
      "4  48.660651  155.330066  342.176581    0.0   9.0  1.0         0.0\n"
     ]
    }
   ],
   "source": [
    "# Using the testing data (30%) predict, get the features and send them in to predict\n",
    "testdata = testingDataFrame[featureColumnNames]\n",
    "results = decisionTreeClassifier.predict(testdata)\n",
    "\n",
    "# Turn the results to pandas dataframe and rename the one column to prediction for easier reading of results.\n",
    "pd_results = pd.DataFrame(results)\n",
    "pd_results.columns = [\"prediction\"]\n",
    "\n",
    "# Merge the test data set with the predictions, but because this is a subset of the main dataset the index of each\n",
    "# row will caust a pandas.concat to give us a jagged matrix. Create a new dataframe with the index reset so that the \n",
    "# concat works as expected.\n",
    "mergetest = testingDataFrame.reset_index(drop=True)\n",
    "resultset = pd.concat([mergetest, pd_results], axis=1)\n",
    "\n",
    "# Visualize a few things\n",
    "print(\"Prediction results using the testing data:\")\n",
    "print(resultset.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research the results of the model\n",
    "\n",
    "Using the test done above, we can determine how the model performed. To do so:\n",
    "    \n",
    "- Use the model to calculate accuracy \n",
    "- Calculate the TP, FP, TN, FN \n",
    "- Calcualte precision, recall and fscore of the model\n",
    "\n",
    "We calculage precision and recall because accuracy is not enough. We should find that the model performs, without any tweaking, \n",
    "at close to 90% but precision and recall are closer to 70%. In a real world situation this likely is not sufficient and would\n",
    "need tweaking by the data scientist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy 0.896108291032149\n",
      "\n",
      "Result set size: 2955\n",
      "\n",
      "Info on devices that are OK:\n",
      "Known good = 2430 , predicted good 2423\n",
      "\n",
      "Info on devices that have failed:\n",
      "Known failed = 525 , predicted failed 532\n",
      "\n",
      "Precision 0.7048872180451128\n",
      "Recall 0.7142857142857143\n",
      "FScore 0.7095553453169348\n"
     ]
    }
   ],
   "source": [
    "#Do some connecting of data to results\n",
    "actualOkState = len(resultset.loc[resultset['state'] == 0.0])\n",
    "actualFailState = len(resultset.loc[resultset['state'] == 1.0])\n",
    "resultOk = len(resultset.loc[resultset['prediction'] == 0.0])\n",
    "resultFail = len(resultset.loc[resultset['prediction'] == 1.0])\n",
    "\n",
    "trueNegative = len(resultset.loc[(resultset['state'] == 0.0) & (resultset['prediction'] == 0.0)]) # TN\n",
    "falsePositive = len(resultset.loc[(resultset['state'] == 0.0) & (resultset['prediction'] == 1.0)]) #FP\n",
    "\n",
    "truePositive = len(resultset.loc[(resultset['state'] == 1.0) & (resultset['prediction'] == 1.0)]) #TP\n",
    "falseNegative = len(resultset.loc[(resultset['state'] == 1.0) & (resultset['prediction'] == 0.0)]) #FN\n",
    "\n",
    "# Precision is percentage of failed prediction that are correct. Where Precision = TP/(TP+FP)\n",
    "precision = truePositive / (truePositive+falsePositive)\n",
    "# Recall is the percentage of failures that correctly identified. Where  Recall = TP/(TP+FN)\n",
    "recall = truePositive / (truePositive+falseNegative)\n",
    "# F score : f = 2*(precision*recall)/(precision + recall)\n",
    "fscore = 2* ((precision*recall)/(precision+recall))\n",
    "\n",
    "#Print out the score of the model and information about the result set\n",
    "print(\"Model accuracy {}\".format(decisionTreeClassifier.score(testdata,testingDataFrame[\"state\"])))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Result set size: {0}\".format(len(resultset)))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Info on devices that are OK:\")\n",
    "print(\"Known good = {} , predicted good {}\".format(actualOkState, resultOk))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Info on devices that have failed:\")\n",
    "print(\"Known failed = {} , predicted failed {}\".format(actualFailState, resultFail))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Precision {}\".format(precision))\n",
    "print(\"Recall {}\".format(recall))\n",
    "print(\"FScore {}\".format(fscore))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "\n",
    "This section will perform the following steps:\n",
    "    \n",
    "- Use pickle to serialize the model to a local file\n",
    "- Upload the model file to an Azure Storage Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local directory already exists!\n",
      "Model file was serialized to local path ./modelfile/factory.pkl\n",
      "Model ./modelfile/factory.pkl was uploaded to storage in readydemo container\n"
     ]
    }
   ],
   "source": [
    "# Create an azure block blob service object\n",
    "az_blob_service = BlockBlobService(account_name=AZURE_STORAGE_ACCOUNT_NAME, account_key=AZURE_STORAGE_ACCOUNT_KEY)\n",
    "\n",
    "# Creat the local directory if not already present\n",
    "if not os.path.exists(LOCAL_SYSTEM_DIRECTORY):\n",
    "    os.makedirs(LOCAL_SYSTEM_DIRECTORY)\n",
    "    print('DONE creating a local directory!')\n",
    "else:\n",
    "    print('Local directory already exists!')\n",
    "    \n",
    "# Open the local file and dump the model to it.    \n",
    "filestream = open(LOCAL_MODEL_FILE, 'wb')\n",
    "pickle.dump(decisionTreeClassifier, filestream)\n",
    "filestream.close()\n",
    "print(\"Model file was serialized to local path {}\".format(LOCAL_MODEL_FILE))\n",
    "\n",
    "# Upload the local file to Azure Storage\n",
    "az_blob_service.create_blob_from_path(\n",
    "    AZURE_STORAGE_CONTAINER_NAME,\n",
    "    AZURE_STORAGE_BLOB_NAME,\n",
    "    LOCAL_MODEL_FILE,\n",
    "    content_settings=ContentSettings(content_type='application/octet-stream'))\n",
    "\n",
    "print(\"Model {} was uploaded to storage in {} container\".format(LOCAL_MODEL_FILE, AZURE_STORAGE_CONTAINER_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the model, de-serialize it and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local model file exists and was deleted\n",
      "Import the model from storage - factory.pkl\n",
      "Model was downloaded from storage and the model re-created.\n",
      "Model accuracy 0.896108291032149\n"
     ]
    }
   ],
   "source": [
    "# Clean up the model (if it exists)\n",
    "if os.path.isfile(LOCAL_MODEL_FILE):\n",
    "    os.remove(LOCAL_MODEL_FILE)\n",
    "    print(\"Local model file exists and was deleted\")\n",
    "    \n",
    "# Pull model back and try to run it\n",
    "az_blob_service.get_blob_to_path(AZURE_STORAGE_CONTAINER_NAME, AZURE_STORAGE_BLOB_NAME, LOCAL_MODEL_FILE)\n",
    "\n",
    "# Load the model from the location it was downloaded\n",
    "print(\"Import the model from storage - {}\".format(AZURE_STORAGE_BLOB_NAME))\n",
    "localFile = open(LOCAL_MODEL_FILE, 'rb')\n",
    "decisionTreeClassifier = pickle.load(localFile)\n",
    "print(\"Model was downloaded from storage and the model re-created.\")\n",
    "\n",
    "#compare the results\n",
    "print(\"Model accuracy {}\".format(decisionTreeClassifier.score(testdata,testingDataFrame[\"state\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dangreadytr1 ubuntuvm",
   "language": "python",
   "name": "dangreadytr1_ubuntuvm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
